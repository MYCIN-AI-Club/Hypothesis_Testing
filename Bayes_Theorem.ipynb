{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Python Programming: Bayes Theorem",
      "provenance": [],
      "collapsed_sections": [
        "Mhgc8dlkL_UT",
        "5Lgaf8JCiI-L"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "8e24f623c9d976e65e43b538ecbbc4d478524c94015e92b14b460358aba5245a"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ],
      "metadata": {
        "id": "Bgp1DV4UuWzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Programming: Bayes Theorem"
      ],
      "metadata": {
        "id": "8flRWHtSHki3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bayes Theorem is applicable in machine learning where we get to use a Bayes classifier inorder to make a prediction. In this session, we will learn how to apply this classifer to a few machine learning problems even though later during Core we will spent time exhaustively on working on such problems. While working, we should note that the bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n",
        "\n",
        "For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n",
        "\n",
        "Such classifiers, Naive Bayes classifiers, are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n"
      ],
      "metadata": {
        "id": "96w9G0XWJrC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example "
      ],
      "metadata": {
        "id": "Mhgc8dlkL_UT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# Example 1\r\n",
        "# ---\r\n",
        "# Let's see an overview on how this classifier works, which suitable applications it has, \r\n",
        "# and how to use it in just a few lines of Python and the Scikit-Learn library.\r\n",
        "# ---\r\n",
        "# Question: Build a very simple SPAM detector for SMS messages given the following dataset; \r\n",
        "# ---\r\n",
        "data = 'https://archive.ics.uci.edu/ml/datasets/sms+spam+collection'\r\n",
        "#"
      ],
      "outputs": [],
      "metadata": {
        "id": "9lBLmRc5HgqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# Importing our library\r\n",
        "# ---\r\n",
        "#\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "GxW80SGJcwPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# Loading our uploaded Data\r\n",
        "# ---\r\n",
        "# We define a separator (in this case, a tab) and rename the columns accordingly\r\n",
        "# \r\n",
        "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\r\n",
        "df.head(50)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ham</td>\n",
              "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spam</td>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>spam</td>\n",
              "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ham</td>\n",
              "      <td>Oh k...i'm watching here:)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ham</td>\n",
              "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ham</td>\n",
              "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>spam</td>\n",
              "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ham</td>\n",
              "      <td>Is that seriously how you spell his name?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ham</td>\n",
              "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ham</td>\n",
              "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ham</td>\n",
              "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ham</td>\n",
              "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ham</td>\n",
              "      <td>Lol your always so convincing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ham</td>\n",
              "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ham</td>\n",
              "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>ham</td>\n",
              "      <td>Wait that's still not all that clear, were you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>ham</td>\n",
              "      <td>K tell me anything about you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>ham</td>\n",
              "      <td>For fear of fainting with the of all that hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>spam</td>\n",
              "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yup... Ok i go home look at the timings then i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>ham</td>\n",
              "      <td>Oops, I'll let you know when my roommate's done</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>ham</td>\n",
              "      <td>I see the letter B on my car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>ham</td>\n",
              "      <td>Anything lor... U decide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hello! How's you and how did saturday go? I wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pls go ahead with watts. I just wanted to be s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>ham</td>\n",
              "      <td>Did I forget to tell you ? I want you , I need...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>spam</td>\n",
              "      <td>07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHO ARE YOU SEEING?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>ham</td>\n",
              "      <td>Great! I hope you like your man well endowed. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>ham</td>\n",
              "      <td>No calls..messages..missed calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>ham</td>\n",
              "      <td>Didn't you get hep b immunisation in nigeria.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>ham</td>\n",
              "      <td>Fair enough, anything going on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yeah hopefully, if tyler can't do it I could m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>ham</td>\n",
              "      <td>U don't know how stubborn I am. I didn't even ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6    ham  Even my brother is not like to speak with me. ...\n",
              "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8   spam  WINNER!! As a valued network customer you have...\n",
              "9   spam  Had your mobile 11 months or more? U R entitle...\n",
              "10   ham  I'm gonna be home soon and i don't want to tal...\n",
              "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
              "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
              "13   ham  I've been searching for the right words to tha...\n",
              "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
              "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
              "16   ham                         Oh k...i'm watching here:)\n",
              "17   ham  Eh u remember how 2 spell his name... Yes i di...\n",
              "18   ham  Fine if thats the way u feel. Thats the way ...\n",
              "19  spam  England v Macedonia - dont miss the goals/team...\n",
              "20   ham          Is that seriously how you spell his name?\n",
              "21   ham    I‘m going to try for 2 months ha ha only joking\n",
              "22   ham  So ü pay first lar... Then when is da stock co...\n",
              "23   ham  Aft i finish my lunch then i go str down lor. ...\n",
              "24   ham  Ffffffffff. Alright no way I can meet up with ...\n",
              "25   ham  Just forced myself to eat a slice. I'm really ...\n",
              "26   ham                     Lol your always so convincing.\n",
              "27   ham  Did you catch the bus ? Are you frying an egg ...\n",
              "28   ham  I'm back &amp; we're packing the car now, I'll...\n",
              "29   ham  Ahhh. Work. I vaguely remember that! What does...\n",
              "30   ham  Wait that's still not all that clear, were you...\n",
              "31   ham  Yeah he got in at 2 and was v apologetic. n ha...\n",
              "32   ham                      K tell me anything about you.\n",
              "33   ham  For fear of fainting with the of all that hous...\n",
              "34  spam  Thanks for your subscription to Ringtone UK yo...\n",
              "35   ham  Yup... Ok i go home look at the timings then i...\n",
              "36   ham    Oops, I'll let you know when my roommate's done\n",
              "37   ham                       I see the letter B on my car\n",
              "38   ham                        Anything lor... U decide...\n",
              "39   ham  Hello! How's you and how did saturday go? I wa...\n",
              "40   ham  Pls go ahead with watts. I just wanted to be s...\n",
              "41   ham  Did I forget to tell you ? I want you , I need...\n",
              "42  spam  07732584351 - Rodger Burns - MSG = We tried to...\n",
              "43   ham                                WHO ARE YOU SEEING?\n",
              "44   ham  Great! I hope you like your man well endowed. ...\n",
              "45   ham                   No calls..messages..missed calls\n",
              "46   ham      Didn't you get hep b immunisation in nigeria.\n",
              "47   ham                    Fair enough, anything going on?\n",
              "48   ham  Yeah hopefully, if tyler can't do it I could m...\n",
              "49   ham  U don't know how stubborn I am. I didn't even ..."
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {
        "id": "NF7rixbGclp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# import pandas as pd\r\n",
        "# # Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\r\n",
        "# df = pd.read_table('SMSSpamCollection',\r\n",
        "#                    sep='\\t',\r\n",
        "#                    header=None,\r\n",
        "#                    names=['label', 'sms_message'])\r\n",
        "# df"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 1. Converting the labels from strings to binary values for our classifier\r\n",
        "# \r\n",
        "df['label'] = df.label.map({'ham': 0, 'spam': 1})\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {
        "id": "cgQU75Rhc2i2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 2. Converting all characters in the message to lower case:\r\n",
        "# \r\n",
        "df['message'] = df.message.map(lambda x: x.lower())\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point, crazy.. available only ...\n",
              "1      0                      ok lar... joking wif u oni...\n",
              "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      0  u dun say so early hor... u c already then say...\n",
              "4      0  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "metadata": {
        "id": "MXLkppitgQ7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 3. Remove any punctuation:\r\n",
        "# \r\n",
        "df['message'] = df.message.str.replace('[^\\w\\s]', '')\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3e50d9ebe58e>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['message'] = df.message.str.replace('[^\\w\\s]', '')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazy available only in ...\n",
              "1      0                            ok lar joking wif u oni\n",
              "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      0        u dun say so early hor u c already then say\n",
              "4      0  nah i dont think he goes to usf he lives aroun..."
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "id": "jG3j0ymwgWOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 4. tokenize the messages into into single words using nltk. \r\n",
        "# First, we have to import and download the tokenizer from the console:\r\n",
        "# \r\n",
        "import nltk\r\n",
        "#nltk.download(\"popular\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "M0B-lfLPgivV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 5. Applying the tokenization. \r\n",
        "# What is tokenization (http://bit.ly/WhatisTokenization)\r\n",
        "# \r\n",
        "df['message'] = df['message'].apply(nltk.word_tokenize)\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  [go, until, jurong, point, crazy, available, o...\n",
              "1      0                     [ok, lar, joking, wif, u, oni]\n",
              "2      1  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3      0  [u, dun, say, so, early, hor, u, c, already, t...\n",
              "4      0  [nah, i, dont, think, he, goes, to, usf, he, l..."
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "metadata": {
        "id": "0Ttknwa9guS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 6. We then perform some word stemming. \r\n",
        "# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \r\n",
        "# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\r\n",
        "# \r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "\r\n",
        "stemmer = PorterStemmer()\r\n",
        " \r\n",
        "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[nah, i, dont, think, he, goe, to, usf, he, li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  [go, until, jurong, point, crazi, avail, onli,...\n",
              "1      0                       [ok, lar, joke, wif, u, oni]\n",
              "2      1  [free, entri, in, 2, a, wkli, comp, to, win, f...\n",
              "3      0  [u, dun, say, so, earli, hor, u, c, alreadi, t...\n",
              "4      0  [nah, i, dont, think, he, goe, to, usf, he, li..."
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "metadata": {
        "id": "4kWxzerKg0V6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 7. We will transform the data into occurrences, \r\n",
        "# which will be the features that we will feed into our model:\r\n",
        "#\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "# This converts the list of words into space-separated strings\r\n",
        "df['message'] = df['message'].apply(lambda x: ' '.join(x))\r\n",
        "\r\n",
        "count_vect = CountVectorizer()\r\n",
        "counts = count_vect.fit_transform(df['message'])\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so earli hor u c alreadi then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goe to usf he live around ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazi avail onli in bugi...\n",
              "1      0                              ok lar joke wif u oni\n",
              "2      1  free entri in 2 a wkli comp to win fa cup fina...\n",
              "3      0        u dun say so earli hor u c alreadi then say\n",
              "4      0  nah i dont think he goe to usf he live around ..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "metadata": {
        "id": "oXv3cwwrhAWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# Pre-processing\r\n",
        "# ---\r\n",
        "# 8. We could leave it as the simple word-count per message, \r\n",
        "# but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf:\r\n",
        "#\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "\r\n",
        "transformer = TfidfTransformer().fit(counts)\r\n",
        "\r\n",
        "counts = transformer.transform(counts)\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so earli hor u c alreadi then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goe to usf he live around ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazi avail onli in bugi...\n",
              "1      0                              ok lar joke wif u oni\n",
              "2      1  free entri in 2 a wkli comp to win fa cup fina...\n",
              "3      0        u dun say so earli hor u c alreadi then say\n",
              "4      0  nah i dont think he goe to usf he live around ..."
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "metadata": {
        "id": "VERkaCMThK8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "# Training the Model\r\n",
        "# ---\r\n",
        "# Now that we have performed feature extraction from our data, \r\n",
        "# it is time to build our model. We will start by splitting our data into training and test sets:\r\n",
        "#\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vksf5PobhVQ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "# Training the Model\r\n",
        "# ---\r\n",
        "# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \r\n",
        "# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited:\r\n",
        "# \r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "\r\n",
        "model = MultinomialNB().fit(X_train, y_train)\r\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "metadata": {
        "id": "PUWlrPzwhfAb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "# Evaluating the Model\r\n",
        "# ---\r\n",
        "# Once we have put together our classifier, we can evaluate its performance in the testing set:\r\n",
        "#\r\n",
        "predicted = model.predict(X_test)\r\n",
        "\r\n",
        "print(np.mean(predicted == y_test))\r\n",
        "\r\n",
        "# Our simple Naive Bayes Classifier has 94.8% accuracy with this specific test set!"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9480286738351255\n"
          ]
        }
      ],
      "metadata": {
        "id": "DT0zZNSkhpvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"green\">Challenges</font>"
      ],
      "metadata": {
        "id": "5Lgaf8JCiI-L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "# Example 1\r\n",
        "# ---\r\n",
        "# In this challenge, we have been tasked with creating a classifier, the training set,\r\n",
        "# then training the classifier using the training set and making a prediction.\r\n",
        "# ---\r\n",
        "# The training set (X) consits of length, weight and shoe size. \r\n",
        "# Y contains the associated labels (male or female).\r\n",
        "# \r\n",
        "\r\n",
        "X = [[121, 80, 44], [180, 70, 43], [166, 60, 38], [153, 54, 37], [166, 65, 40], [190, 90, 47], [175, 64, 39],\r\n",
        "     [174, 71, 40], [159, 52, 37], [171, 76, 42], [183, 85, 43]]\r\n",
        "\r\n",
        "Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male']\r\n",
        "\r\n",
        "# Training the classifier:\r\n",
        "#\r\n",
        "OUR CODE GOES HERE\r\n",
        "\r\n",
        "# Making the prediciton:\r\n",
        "# Using the GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \r\n",
        "# \r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-32-6fda989ce3d4>, line 17)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-6fda989ce3d4>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    OUR CODE GOES HERE\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "metadata": {
        "id": "LG5nw1kRtU0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Example 2\r\n",
        "# ---\r\n",
        "# Question: Use the titanic disaster dataset to create a Gaussian Naive Bayes classifier model \r\n",
        "# (i.e. from sklearn.naive_bayes import GaussianNB) that will make a prediction of survival \r\n",
        "# using passenger ticket fare information. \r\n",
        "# ---\r\n",
        "# Dataset url: http://bit.ly/TitanicDataset \r\n",
        "# \r\n",
        "OUR CODE GOES HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "rHn_lBT8iPVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Example 3\r\n",
        "# ---\r\n",
        "# Question: Create a GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \r\n",
        "# to identify the different species of iris flowers.\r\n",
        "# ---\r\n",
        "# Dataset url = http://bit.ly/MSIrisDatasetNB\r\n",
        "# \r\n",
        "OUR CODE GOES HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "RZizDQj7iQ4O"
      }
    }
  ]
}